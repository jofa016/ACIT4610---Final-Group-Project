{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "955a1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ec266",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52a72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...   \n",
       "1      0                      Ok lar... Joking wif u oni...   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      0  U dun say so early hor... U c already then say...   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                     cleaned_message  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/SMSSpamCollection', sep='\\t', names=['label', 'message'])\n",
    "#df.head()\n",
    "\n",
    "# data cleaning function\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    #remove html tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    #remove urls\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    #remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    #remove emails\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    #remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['cleaned_message'] = df['message'].apply(clean_text)\n",
    "#df.head()\n",
    "\n",
    "# encode labels\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8956b",
   "metadata": {},
   "source": [
    "## Vectorize\n",
    "Vectorizing using TF-IDF(Term Frequency - Inverse Document Frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8e7cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix shape: (5572, 9211)\n",
      "Vocabulary size: 9211\n",
      "['jurong', 'point', 'crazy', 'available', 'bugis', 'great', 'world', 'la', 'buffet', 'cine', 'got', 'amore', 'wat', 'ok', 'lar', 'joking', 'wif', 'oni', 'free', 'entry']\n",
      "Non-zero features in first email: 13\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english'\n",
    "    #ngram_range=(1, 2),\n",
    "    #max_df=0.9,\n",
    "    #min_df=2\n",
    ")\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(df['cleaned_message'])\n",
    "y = df['label'].values\n",
    "\n",
    "print(f\"matrix shape: {X.shape}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "# Save the vectorizer\n",
    "with open('../models/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "# see a few top words\n",
    "print(list(vectorizer.vocabulary_.keys())[:20])\n",
    "\n",
    "# example vector for one email\n",
    "sample_vec = X[0]\n",
    "print(\"Non-zero features in first email:\", sample_vec.nnz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201be7a8",
   "metadata": {},
   "source": [
    "## Train NSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5adf38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c20ce8",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07525ffd",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
