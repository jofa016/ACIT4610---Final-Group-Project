{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "955a1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ec266",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cb52a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/SMSSpamCollection', sep='\\t', names=['label', 'message'])\n",
    "#df.head()\n",
    "\n",
    "# data cleaning function\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    #remove html tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    #remove urls\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    #remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    #remove emails\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    #remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['cleaned_message'] = df['message'].apply(clean_text)\n",
    "#df.head()\n",
    "\n",
    "# encode labels\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8956b",
   "metadata": {},
   "source": [
    "## Vectorize\n",
    "Vectorizing using TF-IDF(Term Frequency - Inverse Document Frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fa8e7cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (5572, 14738)\n",
      "Binary density: 0.001315\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the messages using TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    #stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    max_df=0.9,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(df['cleaned_message'])\n",
    "y = df['label'].values\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", X_tfidf.shape)\n",
    "\n",
    "# Convert to binary inorder to use with NSA\n",
    "tau = 0.05\n",
    "X_binary = (X_tfidf >= tau).astype(np.uint8)\n",
    "\n",
    "#basic diagnostics\n",
    "density = X_binary.nnz / (X_binary.shape[0] * X_binary.shape[1])\n",
    "print(f\"Binary density: {density:6f}\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbff67",
   "metadata": {},
   "source": [
    "- as expected we got total of 5572 messages\n",
    "- we have a large feature space of 51010\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201be7a8",
   "metadata": {},
   "source": [
    "## Train and predict NSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "240e5e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham matrix shape: (4825, 14738)\n",
      "Spam matrix shape: (747, 14738)\n"
     ]
    }
   ],
   "source": [
    "# seperate self(ham) and non-self (spam) \n",
    "X_ham = X_binary[y == 0]\n",
    "X_spam = X_binary[y == 1]\n",
    "\n",
    "print(f\"Ham matrix shape: {X_ham.shape}\")\n",
    "print(f\"Spam matrix shape: {X_spam.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1489b4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham train shape: (3860, 51010)\n",
      "Ham test shape: (965, 51010)\n"
     ]
    }
   ],
   "source": [
    "# split self data into train and test sets\n",
    "X_ham_train, X_ham_test = train_test_split(X_ham, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Ham train shape: {X_ham_train.shape}\")\n",
    "print(f\"Ham test shape: {X_ham_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07525ffd",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8759a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
